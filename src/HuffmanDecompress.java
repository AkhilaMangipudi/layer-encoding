import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.FileReader;
import java.io.BufferedReader;
import java.util.List;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.LinkedList;
import java.util.Queue;
import java.io.InputStreamReader;
import java.util.Map;
import java.util.HashMap;
import java.io.ByteArrayOutputStream;
import org.apache.commons.lang3.StringUtils;

import com.amazonaws.AmazonServiceException;
import com.amazonaws.SdkClientException;
import com.amazonaws.auth.profile.ProfileCredentialsProvider;
import com.amazonaws.regions.Regions;
import com.amazonaws.services.s3.AmazonS3;
import com.amazonaws.services.s3.AmazonS3ClientBuilder;
import com.amazonaws.services.s3.model.GetObjectRequest;
import com.amazonaws.services.s3.model.ResponseHeaderOverrides;
import com.amazonaws.services.s3.model.S3Object;
import com.amazonaws.ClientConfiguration;

/**
 * Decompression application using static Huffman coding.
 * <p>This decompresses the encodings of blocks generated by the "HuffmanCompress" application.</p>
 */
public class HuffmanDecompress {
        /**
        * Decompresses the encodings of the blocks into the block data to form the layer
        * @param versionId versionId of the Huffman tree to be retrieved from Amazon S3
        * @param encodingsList encodings of the blocks in the layer
        * @param hashToBlockBucketName bucketName in S3 which contains the mapping between hash of blocks and their bytes
        * @return byte[] the blockdata in order
        */
        public byte[] decompressLayer(String versionId, List<String> encodingsList, String hashToBlockBucketName) {
                //Using the given versionId, get the serialized string from S3 and deserialize it here to a tree
                String bucketName = "serverless685";
                String key = "huffman";
                S3Object fullObject = null;
                List<String> hashList = new ArrayList<String>();
                ByteArrayOutputStream os = new ByteArrayOutputStream();
                if (versionId.equals("")) {
                        //No huffman tree has been built, the encodingsList contains the hash values directly
                        try {
                                AmazonS3 s3Client = AmazonS3ClientBuilder.standard().withRegion(Regions.US_EAST_2)
                                        .withClientConfiguration(new ClientConfiguration().withMaxConnections(200)).build();
                                os = extractBlocksFromHash(hashToBlockBucketName, encodingsList, s3Client);
                        } catch (AmazonServiceException e) {
                                //This call was transmitted successfully, but S3 couldn't process it
                                e.printStackTrace();
                        } catch (SdkClientException e) {
                                //Amazon S3 couldn't be contacted for a response
                                e.printStackTrace();
                        } catch (IOException e) {
                                e.printStackTrace();
                        }
                        byte[] layerContent = os.toByteArray();
                        System.out.println("Total number of bytes in the layer is " + layerContent.length);
                        return layerContent;
                } else {
                        try {
                                AmazonS3 s3Client = AmazonS3ClientBuilder.standard().withRegion(Regions.US_EAST_2)
                                        .withClientConfiguration(new ClientConfiguration().withMaxConnections(200)).build();
                                fullObject = s3Client.getObject(new GetObjectRequest(bucketName, key, versionId));
                                //Extract the tree as a string from the S3 Object
                                BufferedReader reader = new BufferedReader(new InputStreamReader(fullObject.getObjectContent()));
                                String line = null;
                                String serializedTree = "";
                                while ((line = reader.readLine()) != null) {
                                        serializedTree = serializedTree + line;
                                }

                                Node root = unconvert(serializedTree);
                                for(String encoding: encodingsList) {
                                        //Check if the encoding is alphanumeric or not, if it is, then it means
                                        //it has not been compressed by the huffman tree
                                        if (!encoding.matches("^[01]+$")) {
                                                hashList.add(encoding);
                                        } else {
                                                hashList.add(decode(encoding, root));
                                        }
                                }
                                //Map back the hash values to their byte arrays
                                os = extractBlocksFromHash(hashToBlockBucketName, hashList, s3Client);
                        } catch (AmazonServiceException e) {
                                //This call was transmitted successfully, but S3 couldn't process it
                                e.printStackTrace();
                        } catch (SdkClientException e) {
                                //Amazon S3 couldn't be contacted for a response
                                e.printStackTrace();
                        } catch (IOException e) {
                                e.printStackTrace();
                        }
                        byte[] layerContent = os.toByteArray();
                        System.out.println("Total number of bytes in the layer is " + layerContent.length);
                        return layerContent;
                }
        }

        /**
        * Extracts block data from hash of the blocks
        * @param hashtoBlockBucketName Bucket in S3 which contains the mapping from hash of blocks to block data
        * @param hashList list of Hash values received from server
        * @param s3Client Client to connect to and interact with Amazon S3
        * @return ByteArrayOutputStream Byte stream containing the bytes of all blocks
        */
        public ByteArrayOutputStream extractBlocksFromHash(String hashToBlockBucketName, List<String> hashList, AmazonS3 s3Client) throws IOException {
                ByteArrayOutputStream os = new ByteArrayOutputStream();
                for(String hash : hashList) {
                        S3Object object = s3Client.getObject(new GetObjectRequest(hashToBlockBucketName, hash));
                        int contentLength = (int) object.getObjectMetadata().getContentLength();
                        InputStream in = object.getObjectContent();
                        byte[] bytes = new byte[contentLength];
                        int bytesRead;
                        while((bytesRead = in.read(bytes, 0, contentLength)) != -1) {
                                 os.write(bytes, 0, bytesRead);
                        }
                }
                return os;
        }

        /**
        * To deserialize the object extracted from Amazon S3 to a Huffman tree
        * @param data The string form of the tree extracted from S3
        * @return Node the root of the Huffman tree
        */
        public Node unconvert(String data) {
                return deserialize(new LinkedList<>(Arrays.asList(data.split(","))));
        }

        /**
        * Helper function to deserialize the string into a tree
        */
        private Node deserialize(Queue<String> q) {
                String val = q.poll();
                if("#".equals(val)) return null;
                if("int".equals(val)) {
                        //This is an internal node
                        Node left = deserialize(q);
                        Node right = deserialize(q);
                        Node root = new InternalNode(left, right);
                        return root;
                } else {
                        //Leaf node
                        Node root = new Leaf(val);
                        return root;
                }
        }

        /**
        * Decodes the huffman encoding into the hash value of the block by traversing the huffman tree.
        * For every 0 in the encoded string, left traversal is done and for 1, right traversal is done
        * @param encoding, the encoded string of the hash value of the block
        * @param root, Root of the huffman tree
        * @return String, the hash value of the block
        */
        public String decode(String encoding, Node root) {
                if(root == null) {
                        System.out.println("Root node is null");
                        return "";
                }
                char[] encodingChars = encoding.toCharArray();
                for(int i = 0; i < encodingChars.length; i++) {
                        if (root instanceof InternalNode) {
                                InternalNode node  = (InternalNode)root;
                                if(encodingChars[i] == '0') {
                                        root = (Node)node.leftChild;
                                } else {
                                        root = (Node)node.rightChild;
                                }
                        }
                        else if(root instanceof Leaf) {
                                Leaf leaf = (Leaf)root;
                                return leaf.symbol;
                        }
                }
                if(root instanceof Leaf) {
                        Leaf leaf = (Leaf)root;
                        return leaf.symbol;
                }
                return "";
        }
}
